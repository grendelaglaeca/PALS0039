{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Exercise_2_3.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grendelaglaeca/PALS0039/blob/master/Copy_of_Exercise_2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVyGSWa50Jli"
      },
      "source": [
        "[![PALS0039 Logo](https://www.phon.ucl.ac.uk/courses/pals0039/images/pals0039logo.png)](https://www.phon.ucl.ac.uk/courses/pals0039/)\n",
        "\n",
        "#Exercise 2.3 Vowel Classification Problem\n",
        "\n",
        "In this exercise we implement a system to classify vowels from their formant frequencies. We first explore some characteristics of the data and then implement a simple k-nearest-neghbour classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcxVFZU60ONa"
      },
      "source": [
        "(a) The following code reads in, summarises and generates plots from a data set of vowel formant measurements. Run the code blocks and add comments to describe what is happening in each step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etXkZPRl0GTj"
      },
      "source": [
        "#import the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#read csv file into a var\n",
        "df=pd.read_csv(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/vowels.csv\")\n",
        "\n",
        "# display first 10 rows of data\n",
        "df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYB5NPmY1m8i"
      },
      "source": [
        "# display descriptive stats\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOsBYyfd2E3b"
      },
      "source": [
        "#define plot function to compare y values distribution by sex (x)\n",
        "def plot_compare(data,ylabel):\n",
        "  plt.boxplot(data,labels=(\"male\",\"female\"))\n",
        "  plt.xlabel(\"Sex\")\n",
        "  plt.ylabel(ylabel)\n",
        "\n",
        "# assign columns to variables\n",
        "male=df.loc[df.SEX==\"male\",]\n",
        "female=df.loc[df.SEX==\"female\"]\n",
        "\n",
        "# set plot size\n",
        "plt.figure(figsize=(16,5))\n",
        "\n",
        "# set subplot location and content (compare f1 by sex)\n",
        "plt.subplot(1,3,1)\n",
        "plot_compare([male.F1,female.F1],\"F1 (Hz)\")\n",
        "\n",
        "# subplot 2, same for f2\n",
        "plt.subplot(1,3,2)\n",
        "plot_compare([male.F2,female.F2],\"F2 (Hz)\")\n",
        "\n",
        "# subplot 3 compares participants height by sex \n",
        "plt.subplot(1,3,3)\n",
        "plot_compare([male.HEIGHT,female.HEIGHT],\"Height (cm)\")\n",
        "\n",
        "# display plot\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntNyatxm5Szp"
      },
      "source": [
        "---\n",
        "(b) This code plots an F1-F2 scatter plot in which different vowels are displayed in different colours. Run the code and then add comments to the code to describe what is happening in each step.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2N3kjul5-R1"
      },
      "source": [
        "# convert the vowel series into categories\n",
        "df[\"VOWEL\"]=df.VOWEL.astype(\"category\")\n",
        "print(df.VOWEL.cat.categories)\n",
        "\n",
        "# set up a series in which the vowels are stored as numbers \n",
        "df[\"VOWELIDX\"]=df.VOWEL.cat.codes\n",
        "print(df.VOWELIDX)\n",
        "\n",
        "# set the plot size, choose scatterplot, add colour mapping\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(df.F2,df.F1,c=df.VOWELIDX,cmap=\"tab10\")\n",
        "plt.axis([3000,500,1100,100])\n",
        "plt.xlabel(\"F2 (Hz)\")\n",
        "plt.ylabel(\"F1 (Hz)\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnC34v3Xz_bw"
      },
      "source": [
        "---\n",
        "(c) This code builds a simple vowel classifier based on formant frequencies. It works by taking each vowel in turn and find the 5 closest other vowels - then selecting a label based on the most commonly found neaest vowel.\n",
        "\n",
        "Run the code then add comments describing what is happening in each step.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiRORZ_mzvey"
      },
      "source": [
        "# import the square root function\n",
        "from math import sqrt\n",
        "\n",
        "# calculate the euclidean distance between rows\n",
        "def distance(df,row1,row2):\n",
        "  return(sqrt((df.F1[row1]-df.F1[row2])**2+(df.F2[row1]-df.F2[row2])**2))\n",
        "\n",
        "# get the nearest neighbours of a given row\n",
        "def getneighbours(df,row,n=5):\n",
        "  # get table of all the inter-row distances\n",
        "  distances = []\n",
        "  for i in range(len(df)):\n",
        "    distances.append(distance(df,row,i))\n",
        "  # list the indexes of the distances sorted by value\n",
        "  index=np.argsort(distances)\n",
        "  # choose the rows with the n nearest distances (excluding the original)\n",
        "  neighbours = df.index.values[index[1:n+1]]\n",
        "  # return the best rows\n",
        "  return neighbours\n",
        "\n",
        "# find the most frequently occuring vowel among the 5 nearest neighbours\n",
        "def vote(df,neighbours):\n",
        "  # Return a series containing counts of unique values starting with most frequent\n",
        "  # (get table of counts ordered by frequency)\n",
        "  counts=df.loc[neighbours,\"VOWEL\"].value_counts()\n",
        "  # return the index of the most frequent vowel\n",
        "  return counts.index[0]\n",
        "\n",
        "# read the vowel formant data \n",
        "df=pd.read_csv(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/vowels.csv\")\n",
        "\n",
        "# apply the classifier to the whole dataset\n",
        "# (this is called: leave one out cross-validation)\n",
        "correct=0\n",
        "total=0\n",
        "for i in range(len(df)):\n",
        "  # for each row in df get 5 nearest neighbors \n",
        "  neighbours=getneighbours(df,i)\n",
        "  # choose the most common vowel among the nearest neighbours\n",
        "  # print row, matching vowel,  \n",
        "  vowel=vote(df,neighbours)\n",
        "  print(i,df.VOWEL[i],vowel)\n",
        "  # if the chosen vowel is correct, keep tally\n",
        "  if (df.VOWEL[i]==vowel):\n",
        "    correct += 1\n",
        "  total += 1\n",
        "\n",
        "# report performance: \n",
        "# calculate the number of correctly classified vowels, total and success percentage\n",
        "print(\"Correct = %d/%d (%.1f%%)\" % (correct,total,100.0*correct/total))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKfMZaBgthIx"
      },
      "source": [
        "---\n",
        "(d) This code converts the F1 and F2 frequencies to z-scores for each speaker individually. Run the code then add comments describing what is happening in each step.\n",
        "\n",
        "This code is rather inefficient - can you see why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdtWhHg_Elnn"
      },
      "source": [
        "#read in the vowel data\n",
        "df=pd.read_csv(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/vowels.csv\")\n",
        "\n",
        "#for each row (vowel) in df:\n",
        "for i in range(len(df)):\n",
        "  #assign speaker's ID to a var\n",
        "  spkr=df.SPEAKER[i];\n",
        "  #assign subset data for this speaker into dfs var\n",
        "  dfs=df.loc[df.SPEAKER==spkr,]\n",
        "  #get means and SDs for this speaker's F1 and F2\n",
        "  mnf1=dfs.F1.mean()\n",
        "  sdf1=dfs.F1.std()\n",
        "  mnf2=dfs.F2.mean()\n",
        "  sdf2=dfs.F2.std()\n",
        "  #normalize F1 and F2 for this vowel\n",
        "  #add a column to the speaker's data, with values converted to z-scores\n",
        "  df.at[i,\"F1norm\"]=(df.F1[i]-mnf1)/sdf1\n",
        "  df.at[i,\"F2norm\"]=(df.F2[i]-mnf2)/sdf2\n",
        "\n",
        "#displa\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f1me1ABFOIP"
      },
      "source": [
        "---\n",
        "(e) This code also converts the F1 and F2 frequencies to z-scores but in a more efficient manner. Run the code and add comments describing what is happening in each step.\n",
        "\n",
        "Why is this code more efficient?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUQRFgQaJKIh"
      },
      "source": [
        "#this code doesn't iterate through each row, instead first groups the data points\n",
        "#by speaker id and maps the function over arrays\n",
        "\n",
        "#assign vowel data into a var\n",
        "df=pd.read_csv(\"https://www.phon.ucl.ac.uk/courses/pals0039/data/vowels.csv\")\n",
        "\n",
        "#group each speaker's data, aggregate means and SDs into variables\n",
        "means=df.groupby(['SPEAKER']).agg(\"mean\")\n",
        "stds=df.groupby(['SPEAKER']).agg(\"std\")\n",
        "\n",
        "#convert means and SDs for the speaker's F1 and F2 into numpy arrays\n",
        "#(replicate means and sds to one per vowel)\n",
        "F1mean=means.F1[df.SPEAKER].to_numpy()\n",
        "F1std=stds.F1[df.SPEAKER].to_numpy()\n",
        "F2mean=means.F2[df.SPEAKER].to_numpy()\n",
        "F2std=stds.F2[df.SPEAKER].to_numpy()\n",
        "\n",
        "#create new column with normalized f1 and f2 (z-scores) \n",
        "# (process all vowels at the same time)\n",
        "df[\"F1norm\"]=(df.F1-F1mean)/F1std\n",
        "df[\"F2norm\"]=(df.F2-F2mean)/F2std\n",
        "\n",
        "#\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vSoyjzrFlsE"
      },
      "source": [
        "(f) Write code to run the nearest neighbour classifier again using the normalised F1 and F2 data.\n",
        "\n",
        "**Hint:** you will need to re-use code from block (c) but with the F1norm and F2norm values replacing the F1 and F2 values.\n",
        "\n",
        "Why is performance better after normalisation?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb-cfEo38Yl7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}